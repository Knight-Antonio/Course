{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import keras.models \n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Activation, Conv2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Lambda\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (45000, 32, 32, 3)\n",
      "45000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "split_rate = 0.1\n",
    "def split_validation(train, split_rate):\n",
    "    validation_index = int(len(train) * split_rate);\n",
    "    validation = train[-validation_index:];\n",
    "    train = train[:-validation_index];\n",
    "    return train, validation\n",
    "batch_size = 32 \n",
    "num_classes = 10\n",
    "epochs = 500\n",
    "data_augmentation = True\n",
    "# Load cifar10 data and split train data to get validation data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_validation = split_validation(x_train, split_rate)\n",
    "y_train, y_validation = split_validation(y_train, split_rate)\n",
    "x_train = x_train.astype('float32')\n",
    "x_validation = x_validation.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_validation /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_validation = keras.utils.to_categorical(y_validation, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 32, 32, 96)        83040     \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 16, 16, 96)        83040     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 16, 16, 192)       166080    \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 16, 16, 192)       331968    \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 192)         768       \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 8, 8, 192)         37056     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 8, 8, 10)          1930      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,370,890\n",
      "Trainable params: 1,370,314\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(96, (3, 3), padding = 'same', input_shape=(32, 32, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(96, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(96, (3, 3), padding='same', strides = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(192, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(192, (3, 3), padding='same', strides = (2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(192, (1, 1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(10, (1, 1), padding='same'))\n",
    "\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    # Learning Rate Schedule\n",
    "    lr = 0.05\n",
    "    if epoch > 200:\n",
    "        lr *= 0.1\n",
    "    if epoch > 250:\n",
    "        lr *= 0.1\n",
    "    if epoch > 300:\n",
    "        lr *= 0.1\n",
    "    \n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"AllConv_model.h5\"\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph', \n",
    "                                         histogram_freq=0, \n",
    "                                         write_graph=True, \n",
    "                                         write_images=True)\n",
    "\n",
    "callbacks_list = [checkpoint, tbCallBack, lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False) \n",
    "\n",
    "datagen.fit(x_train)\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=epochs, \n",
    "                    validation_data=(x_validation, y_validation), \n",
    "                    callbacks=callbacks_list, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 152us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4767506147934124, 0.912]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('model/AllConv_model.h5');\n",
    "model.evaluate(x=x_test, y=y_test, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
